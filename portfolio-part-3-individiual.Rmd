---
title: "Methods 4 -- Portfolio Assignment 3"
output:
  html_document:
    df_print: paged
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(fig.width = 10, warning = FALSE)

library(tidyverse)
library(LaplacesDemon)
library(rethinking)
library(dagitty)
library(ggdag)
library(truncnorm)

n_cores <- parallel::detectCores()
n_chains <- 8
n_iter <- 3000
options(mc.cores = n_cores)

# set random seed for reproducibility
set.seed(133742)
options(digits = 3)
.pardefault <- par()

```

## Luke Ring: 202009983

- *Type:* Individual assignment
- *Due:* 1 May 2022, 23:59

Hey again CogSci\'s :)

So now for the last of the three portfolios :)

This time it\'s an individual one. We will build a workflow and use it
to analyze a new dataset.

There are seven tasks below. As usual, handing in as a markdown is nice
:)

## 1. Get familiar with the data

It is a dataset containing information about the people who were on the
Titanic when it sank. Our job is to find out why some survived, and
others didn\'t.

The data is downloaded from [Kaggle](https://www.kaggle.com/).
You can get it on this link:

[https://www.kaggle.com/competitions/titanic/data](https://www.kaggle.com/competitions/titanic/data)

But if you don\'t want to make an account there, we have also put it in the
`data/` directory in the repository :) It's entirely fine for you to use the
combined training and test datasets for your analysis, but if you like, you can
develop your analysis on the training set and validate it on the test set.
(Bonus question: what are the advantages and disadvantages of either approach?)

Get an overview of which variables are in the dataset.

```{r overview_data}
# read in data
data_train <- read.csv("data/titanic_train.csv")
data_test <- read.csv("data/titanic_test.csv")
head(data_train)
summary(data_train)
```

| Variable | Type |
|----------|------|
| Survived | int (1/0) |
| Pclass | int (1/2/3) |
| Name | str |
| Sex | male/female |
| Age | int |
| SibSp | int number of siblings or spouses on board |
| Parch | int number of parents / children on board |
| Ticket | str |
| Fare | float |
| Cabin | str |
| Embarked | char, port C = Cherbourg, Q = Queenstown, S = Southampton |


Do some quick plots to get a sense of how the data looks.

  
```{r plots}
data_train$Survived <- as.logical(data_train$Survived)

data_train$Pclass <- as.factor(data_train$Pclass)
data_test$Pclass <- as.factor(data_test$Pclass)

data_train$Sex <- as.factor(data_train$Sex)
data_test$Sex <- as.factor(data_test$Sex)



# plot data
ggplot(
  data_train,
  aes(
    x = Sex,
    y = Survived,
    color = Pclass)) +
  geom_jitter()

# plot variables
ggplot(
    data_train,
    aes(x = Survived, fill = Survived)
  ) +
  geom_bar() +
  geom_text(aes(
      group = Survived, label = after_stat(count), vjust = 2),
      stat = "count", position = position_fill()) +
  labs(
    title = "Survived",
  )

ggplot(
    data_train,
    aes(x = Pclass)
  ) +
  geom_bar(aes(group = Survived, fill = Survived)) +
  geom_text(aes(
      group = Survived, label = after_stat(count)), vjust = 2,
    stat = "count", position = "stack") +
  geom_text(aes(
      label = after_stat(paste("Total: ", count))), vjust = 2,
      stat = "count", position = position_fill()) +
  labs(
    title = "Passenger Class",
  )

ggplot(
    data_train,
    aes(x = Sex)
  ) +
  geom_bar(aes(group = Survived, fill = Survived)) +
  geom_text(aes(
      group = Survived,
      label = after_stat(count)), vjust = 2,
    stat = "count", position = "stack") +
  geom_text(aes(
      label = after_stat(paste("Total: ", count))), vjust = 2,
      stat = "count", position = position_fill()) +
  labs(
    title = "Passenger Sex",
  )

data_train %>%
  filter(!is.na(Age)) %>%
  ggplot(
    aes(x = Age)
  ) +
  geom_point(
    aes(
      group = Survived,
      color = Survived,
      size = after_stat(count)),
    stat = "count", na.rm = TRUE) +
  labs(
    title = "Passenger survival by Age",
  )

data_train %>%
  filter(!is.na(Age)) %>%
  group_by(Age, Survived) %>%
  summarise(freq = n(), Age = Age, Survived = Survived, .groups = "keep") %>%
  ggplot(
    aes(x = Age, y = freq)
  ) +
  geom_smooth(aes(color = Survived), method = loess, formula = y ~ x) +
  labs(
    title = "Frequency plot of passenger survival by age",
  )

data_train %>%
  filter(!is.na(Age)) %>%
  group_by(Age) %>%
  summarise(
    Age = Age,
    survival_prop = sum(Survived) / n(),
    .groups = "keep") %>%
  ggplot(
    aes(x = Age, y = survival_prop)
  ) +
  geom_smooth(method = loess, formula = y ~ x) +
  labs(
    title = "Proportional passenger survival by Age",
  )

hist(data_train$Age, breaks = 80)

```

> Visual inspection of the data shows that proportionally more female passengers survived than males, and it seems like proportionally the highest death rate comes from third class passengers (also by total numbers). It also seems like including age would be relevant, also just by reasoning based on the cultural meme of "saving the women and children".
> 
> It's possible that passenger class has an effect on age (i.e. it's possible that passengers of a certain class were more likely to bring children, or people of a certain age are more likely to be able to afford first class tickets).
>
> Let's briefly look at the data to see if the idea is supported.

```{r class_and_age}


by_age_pclass <- data_train %>%
  filter(!is.na(Age))

by_age_pclass %>%
  ggplot(aes(x = Age, group = Pclass, fill = Pclass)) +
  stat_bin(
    binwidth = 5,
    geom = "bar",
    position = position_dodge()
  ) +
  stat_bin(
    aes(label = ..count..),
    binwidth = 5,
    geom = "text",
    position = position_dodge(width = 5), vjust = -1
  )

passengers_by_class <- c(
  1 / nrow(by_age_pclass[by_age_pclass$Pclass == 1, ]),
  1 / nrow(by_age_pclass[by_age_pclass$Pclass == 2, ]),
  1 / nrow(by_age_pclass[by_age_pclass$Pclass == 3, ]))
  
by_age_pclass %>%
  mutate(
    bin = cut(Age, breaks = seq(0, 85, by = 5)),
    p_by_class = passengers_by_class[Pclass]) %>%
  group_by(bin, Pclass) %>%
  summarise(
    bin = bin,
    Pclass = Pclass,
    Age = Age,
    n_prop_c = sum(p_by_class), .groups = "drop") %>%
  group_by(bin) %>%
  summarise(
    bin = bin,
    Pclass = Pclass,
    Age = Age,
    n_prop_a = n_prop_c / sum(n_prop_c), .groups = "drop") %>%
  group_by(bin, Pclass) %>%
  summarise(
    bin = bin,
    Pclass = Pclass,
    Age = Age,
    n_prop_ac = sum(n_prop_a), .groups = "drop") %>%
  ggplot(
    aes(x = bin, y = n_prop_ac, fill = Pclass, color = Pclass)
  ) +
  geom_col(position = position_dodge()) +
  labs(
    title = "Passenger class by Age (proportional)",
  )

```

> So it does seem at least with the 40+ passengers, more were first class, and the inverse for below 40.
> Roughly eyeballing it you could say the mean age of first class passengers is around 40, second class: 35, and the mean age of third class passengers is around 30.
>

## 2. Choose an estimand / outcome

We recommend that you choose whether the person survived as the
outcome - it\'s (a bit) interesting, and it forces you to do regression
with a binary outcome :)

However, it\'s okay to do something else if you really want to :)

> `Survived` is the outcome we are trying to predict. 

## 3. Make a scientific model (i.e., a DAG)

Make a DAG that seems theoretically reasonable, and that includes some
of the variables in the dataset. It can include unobserved variables
too, if you want, but then you have to come up with them.

You might have to return to this point later on ;)

```{r dag}

dagtanic <- dagitty(
  "dag {
    A -> S
    Sx -> S
    C -> S
    A -> C
  }"
)
tidy_dagtanic <- tidy_dagitty(dagtanic)

ggdag(tidy_dagtanic, stylized = TRUE) +
  theme_dag() +
  geom_dag_edges_link(
    arrow = grid::arrow(
      length = grid::unit(16, "pt"),
      type = "closed")) +
  ggtitle("DAG of Titanic survival")

ggdag_equivalent_dags(tidy_dagtanic, stylized = TRUE) +
  theme_dag() +
  geom_dag_edges_link(
    arrow = grid::arrow(
      length = grid::unit(16, "pt"),
      type = "closed")) +
  ggtitle("Equivalent DAGs")

adjustmentSets(dagtanic, exposure = c("C", "Sx"), outcome = "S")

adjustmentSets(dagtanic, exposure = c("C", "Sx", "A"), outcome = "S")

impliedConditionalIndependencies(dagtanic)

```

> Based on the dag and running adjustmentSets, we should use Passenger Class, Sex and Age with the outcome of Survived. We only have implied conditional independencies for Age and Sex and Passenger class and Sex.

## 4. Simulate data from the DAG

Use some reasonable or expected parameter values.

Use this to see if the DAG can give data that looks similar to what you
have.

Maybe plot the simulated data to see if it looks right.

Also, this is one of those things which is nice to get comfy with :)

```{r simulate}


n_sim <- 1000

s_age <- c(
  rtruncnorm(n_sim / 16, a = 0, b = 80, mean = 0, sd = 3),
  rtruncnorm(n_sim + 1 - n_sim / 16, a = 0, b = 80, mean = 30, sd = 15))

b_age_pclass <- 0.1

age_to_class_probabilities <- function(age) {
  if (age < 40) {
    c(0.2, 0.1, 0.7)
  } else {
    c(0.8, 0.1, 0.1)
  }
}

b_pclass <- c(0.22, 0.18, 0.6)
pr_age_pclass <- matrix(sapply(s_age, age_to_class_probabilities),
  ncol = 3, nrow = n_sim)

p_age_pclass <- matrix(
  c(
    # base probability of class plus probability of class  by age
    (1 - b_age_pclass) * b_pclass[1] + b_age_pclass * pr_age_pclass[, 1],
    (1 - b_age_pclass) * b_pclass[2] + b_age_pclass * pr_age_pclass[, 2],
    (1 - b_age_pclass) * b_pclass[3] + b_age_pclass * pr_age_pclass[, 3]
  ),
  ncol = 3, nrow = n_sim)

p_age_pclass <- p_age_pclass / rowSums(p_age_pclass)

s_pclass <- rcat(n_sim, p = p_age_pclass)

# as age increases, less likely to survive (in general)
p_age_survival <- 1 - (0.2 + s_age * 1 / 80 * 0.7)

s_sex <- rbinom(n_sim, p = 0.65, size = 1) + 1

# sex effect on survival F, M
bSxS <- c(0.75, 0.2)
# class effect on survival, 1, 2, 3
bCS <- c(0.65, 0.5, 0.25)

bSxCS <- c(
  (bSxS[1] + bCS[1]) / sum(bSxS, bCS),
  (bSxS[2] + bCS[1]) / sum(bSxS, bCS),
  (bSxS[1] + bCS[2]) / sum(bSxS, bCS),
  (bSxS[2] + bCS[2]) / sum(bSxS, bCS),
  (bSxS[1] + bCS[3]) / sum(bSxS, bCS),
  (bSxS[2] + bCS[3]) / sum(bSxS, bCS)
)

p_survival <- matrix(bSxCS, nrow = 2, ncol = 3)

s_survival <- rbern(n_sim, p_survival[s_sex, s_pclass] * p_age_survival)

dens(s_age, adj = 0.1)
hist(s_sex)
hist(s_pclass)
hist(s_survival)

d_sim <- list(
  Age = standardize(s_age),
  Sex = s_sex,
  Pclass = s_pclass,
  Survived = s_survival
)

```

> This simulated data looks pretty good, it seems to mirror the real data fairly well.

## 5. Make a statistical model

The whole thing :)

Include relevant predictors.

Remember to check for adjustment sets.

Figure out how to deal with binary and categorical variables.

Include interactions maybe.

Set priors. Use prior predictive checks for that.

Use MCMC to fit it. You can also try with quap and see if there\'s a
difference.

```{r model, warning=FALSE}
# cmdstan caused an issue with later tidybayes
set_ulam_cmdstan(FALSE)
rstan_options(auto_write = TRUE)

d <- list(
  Age = standardize(by_age_pclass$Age),
  Pclass = as.integer(by_age_pclass$Pclass),
  Survived = as.integer(by_age_pclass$Survived),
  Sex = as.integer(by_age_pclass$Sex))

m_v <- alist(
  Survived ~ dbern(p),
  logit(p) <- a + b_cls[Pclass] + b_sex[Sex] + b_age * Age,
  a ~ dnorm(-0.2, 1),
  b_cls[Pclass] ~ dnorm(0, 1),
  b_sex[Sex] ~ dnorm(0, 1),
  b_age ~ dnorm(-0.1, 1)
)

m1 <- ulam(
  m_v,
  data = d,
  chains = n_chains,
  iter = n_iter,
  cores = n_cores,
  log_lik = TRUE,
  messages = FALSE,
  refresh = 0
)

precis(m1, depth = 2)
precis_plot(precis(m1, depth = 2))

trankplot(m1,
  pars = c(
    "a",
    "b_cls[1]",
    "b_cls[2]",
    "b_cls[3]",
    "b_sex[1]",
    "b_sex[2]",
    "b_age"))


# take a look at our priors
pr <- extract.prior(m1, refresh = 0)

pr_p <- link(m1, data = d, post = pr)

pr_p_m <- rowMeans(pr_p)
p <- inv_logit(pr_p_m)
par(.pardefault)
dens(p, adj = 0.1)
```

> As found in section 3, if we predict survival by class and age we should not have any backdoor paths according to our dag.
> The priors look good, initially I tried to use more informed priors but it got messy quickly, I think it seems like an ok balance.

## 6. Test the statistical model on the simulated data

Test that the conditional independencies implied by the DAG are also in
the simulated data. If they aren\'t, something\'s probably wrong.

> The implied conditional independencies found in our dag were:
> 
> - A \_||\_ Sx
> - C \_||\_ Sx

```{r test_sim, warning=FALSE}
# first lest run our model on the simulated data

m1_sim <- ulam(
  m_v,
  data = d_sim,
  chains = n_chains,
  iter = n_iter,
  cores = n_cores,
  log_lik = TRUE,
  messages = FALSE,
  refresh = 0
)

precis(m1_sim, depth = 2)
precis_plot(precis(m1_sim, depth = 2))

trankplot(m1_sim,
  pars = c(
    "a",
    "b_cls[1]",
    "b_cls[2]",
    "b_cls[3]",
    "b_sex[1]",
    "b_sex[2]",
    "b_age"))


# checking independence of age and sex
m2_A_Sx <- ulam(
  alist(
    Age ~ dnorm(mu, sigma),
    mu <- a + b_sex[Sex],
    a ~ dnorm(0, 1),
    b_sex[Sex] ~ dnorm(0, 1),
    sigma ~ dexp(1)
  ),
  data = d_sim,
  chains = 8,
  cores = n_cores,
  log_lik = TRUE,
  messages = FALSE,
  refresh = 0
)

precis(m2_A_Sx, depth = 2)
par(.pardefault)
precis_plot(precis(m2_A_Sx, depth = 2))

# outcome is expected to be [0,1]
d_sim_S <- d_sim
d_sim_S$Sex <- d_sim_S$Sex - 1

# checking independence of sex and class
m2_Sx_C <- ulam(
  alist(
    Sex ~ dbern(p),
    logit(p) <- a + b_cls[Pclass],
    a ~ dnorm(0, 1),
    b_cls[Pclass] ~ dnorm(0, 1)
  ),
  data = d_sim_S,
  chains = n_chains,
  iter = n_iter,
  cores = n_cores,
  log_lik = TRUE,
  messages = FALSE,
  refresh = 0
)

precis(m2_Sx_C, depth = 2)
par(.pardefault)
precis_plot(precis(m2_Sx_C, depth = 2))

```

> Both conditional independencies stand in the simulated data (with largely overlapping confidence intervals). Running the model on the simulated data also gives us a healthy looking chain on inspection (chain 1).


## 7. Assess whether the DAG is compatible with the data

Check the conditional independencies implied by the DAG are in the real
data.

Remember adjustment sets. If they aren\'t, make a new DAG.

```{r test_real, warning=FALSE}
# checking independence of age and sex
m2_A_Sx <- ulam(
  alist(
    Age ~ dnorm(mu, sigma),
    mu <- a + b_sex[Sex],
    a ~ dnorm(0, 1),
    b_sex[Sex] ~ dnorm(0, 1),
    sigma ~ dexp(1)
  ),
  data = d,
  chains = n_chains,
  iter = n_iter,
  cores = n_cores,
  log_lik = TRUE,
  messages = FALSE,
  refresh = 0
)

precis(m2_A_Sx, depth = 2)
precis_plot(precis(m2_A_Sx, depth = 2))

# outcome is expected to be [0,1]
d_S <- d
d_S$Sex <- d$Sex - 1

# checking independence of sex and class
m2_Sx_C <- ulam(
  alist(
    Sex ~ dbern(p),
    logit(p) <- a + b_cls[Pclass],
    a ~ dnorm(0, 1),
    b_cls[Pclass] ~ dnorm(0, 1)
  ),
  data = d_S,
  chains = n_chains,
  iter = n_iter,
  cores = n_cores,
  log_lik = TRUE,
  messages = FALSE,
  refresh = 0
)

precis(m2_Sx_C, depth = 2)
precis_plot(precis(m2_Sx_C, depth = 2))

```

> As with the simulated data, the conditional independencies stand in the real data, there may be some kind of extremely weak effect but with error bars so large there's no way to really tell, perhaps if there were more people or more Titanics we'd get enough data to pin it down. 
>
> With the C \_||\_ Sx we see that perhaps that classes have a different proportion of male and female passengers, but again it would be hard to say this would hold with more data, maybe rich bachelors were more likely to buy first class tickets?


## 8. Do model comparison

Try out some different priors.

Try with and without interactions.

Use Cross-Validation, PSIS and/or WAIC.

Use posterior predictive checks to make sure that the models don\'t make
crazy predictions.

Select a model that you find reasonable. If none are, make a new one.

> first  let's investigate some different priors

```{r model_comparison, warning=FALSE}

m1_broad_priors <-  ulam(
  alist(
    Survived ~ dbern(p),
    logit(p) <- a + b_cls[Pclass] + b_sex[Sex] + b_age * Age,
    a ~ dnorm(0, 10),
    b_cls[Pclass] ~ dnorm(0, 10),
    b_sex[Sex] ~ dnorm(0, 10),
    b_age ~ dnorm(0, 10)
  ),
  data = d,
  chains = n_chains,
  iter = n_iter,
  cores = n_cores,
  log_lik = TRUE,
  messages = FALSE,
  refresh = 0,
  # default max treedepth (10) for this model results in errors
  control = list(max_treedepth = 20)
)

precis(m1_broad_priors, depth = 2)
precis_plot(precis(m1_broad_priors, depth = 2))

m1_narrower_priors <-  ulam(
  alist(
    Survived ~ dbern(p),
    logit(p) <- a + b_cls[Pclass] + b_sex[Sex] + b_age * Age,
    a ~ dnorm(0, 0.25),
    b_cls[Pclass] ~ dnorm(0, 0.25),
    b_sex[Sex] ~ dnorm(0, 0.25),
    b_age ~ dnorm(0, 0.25)
  ),
  data = d,
  chains = n_chains,
  iter = n_iter,
  cores = n_cores,
  log_lik = TRUE,
  messages = FALSE,
  refresh = 0
)

precis(m1_narrower_priors, depth = 2)
precis_plot(precis(m1_narrower_priors, depth = 2))

m1_narrowest_priors <-  ulam(
  alist(
    Survived ~ dbern(p),
    logit(p) <- a + b_cls[Pclass] + b_sex[Sex] + b_age * Age,
    a ~ dnorm(0, 0.1),
    b_cls[Pclass] ~ dnorm(0, 0.1),
    b_sex[Sex] ~ dnorm(0, 0.1),
    b_age ~ dnorm(0, 0.1)
  ),
  data = d,
  chains = n_chains,
  iter = n_iter,
  cores = n_cores,
  log_lik = TRUE,
  messages = FALSE,
  refresh = 0
)

precis(m1_narrowest_priors, depth = 2)
precis_plot(precis(m1_narrowest_priors, depth = 2))

```

> With much broader priors we can see that the model isn't able to find precise values for the parameters.
>
> With more narrow priors, as expected the standard deviation is lower, but we also see smaller differences in mean values. If the mean values are accurate this could be a good thing.

  
```{r model_comparison_cont, warning=FALSE}
# include interaction between class and age
m3 <- ulam(
  alist(
    Survived ~ dbern(p),
    logit(p) <- a + b_sex[Sex] + b_cls[Pclass] * Age,
    a ~ dnorm(0, 1),
    b_cls[Pclass] ~ dnorm(0, 1),
    b_sex[Sex] ~ dnorm(0, 1)
  ),
  data = d,
  chains = n_chains,
  iter = n_iter,
  cores = n_cores,
  log_lik = TRUE,
  messages = FALSE,
  refresh = 0
)

precis(m3, depth = 2)
precis_plot(precis(m3, depth = 2))


# simple prediction of survival from age
m4 <- ulam(
  alist(
    Survived ~ dbern(p),
    logit(p) <- a + b_age * Age,
    a ~ dnorm(0, 1),
    b_age ~ dnorm(0, 1)
  ),
  data = d,
  chains = n_chains,
  iter = n_iter,
  cores = n_cores,
  log_lik = TRUE,
  messages = FALSE,
  refresh = 0
)

precis(m4, depth = 2)
precis_plot(precis(m4, depth = 2))

# intercept per class and sex
m5 <- ulam(
  alist(
    Survived ~ dbern(p),
    logit(p) <- a[Sex, Pclass] + b_age * Age,
    matrix[Sex, Pclass]:a ~ normal(0, 1),
    b_age ~ dnorm(0, 1)
  ),
  data = d,
  chains = n_chains,
  iter = n_iter,
  cores = n_cores,
  log_lik = TRUE,
  messages = FALSE,
  refresh = 0
)

precis(m5, depth = 3)
precis_plot(precis(m5, depth = 3))


model_comp <- compare(
  m1,
  m1_broad_priors,
  m1_narrower_priors,
  m1_narrowest_priors,
  m3,
  m4,
  m5,
  n = 5000)
model_comp
plot(model_comp)

postcheck(m5, window = 100)


# PSIS takes 10+ minutes and gave exactly the same results as WAIC
# compare(
#   m1,
#   m1_broad_priors,
#   m1_narrower_priors,
#   m1_narrowest_priors,
#   m3,
#   m4,
#   m5,
#   func = PSIS,
#   n = 5000)
```

> Model comparison shows our most complex model has the best results (m5, which includes modelling intercepts for combinations of passenger class and sex).
> also interesting to note that the model predicting survival from age alone (m4) suggests that ther may be a weak effect, but at the same time, our graphs earlier indicated a more complex (i.e. parabolic) relationship between age and survival, which could fit with the idea of saving young children.

## 9. Use the statistical model to do inference

Time to answer the question: which things determine whether people died
at Titanic? (or maybe you made some other question that\'s also okay).

What are the effect sizes? What are their directions?

Make a tiny conclusion here. Maybe try and give a theoretical reason for
your results.

And drink some tea or coffee :)


```{r model_inference, warning=FALSE}
library(modelr)
library(tidybayes)
library(tidybayes.rethinking)


d_df <- as.data.frame(d)
d_df$Survived <- as.logical(d_df$Survived)
m5 <- recover_types(m5, d_df)

d_df %>%
  data_grid(Sex, Pclass, Age) %>%
  add_predicted_draws(m5) %>%
  mutate(Survived = as.logical(.prediction)) %>%
  ggplot(aes(x = Survived)) +
  geom_bar(
    aes(
      y = after_stat(count / tapply(count, PANEL, sum)[PANEL] * 100),
      fill = "Actual Data"),
    data = d_df,
    position = position_dodge2(width = 0.5, padding = 0.5)) +
  geom_bar(
    aes(
      y = after_stat(count / tapply(count, PANEL, sum)[PANEL] * 100),
      fill = "Model Predicted"),
      width = 0.5,
      position = position_dodge2(width = 0.5, padding = -0.5)) +
  scale_fill_manual(
    name = "Source",
    values = c("#0000ff8b", "#6ad0ff93")) +
  facet_grid(vars(Sex), vars(Pclass),
    labeller = labeller(
    .rows = c("1" = "Female", "2" = "Male"),
    .cols = c("1" = "1st Class", "2" = "2nd Class", "3" = "3rd Class")
  )) +
  labs(
    title = "Proportional survival rate of passengers",
    x = "Survived",
    y = "Percentage of passengers (by Sex and Class)")

# test our predictions with our best model
mu <- link(m5)
mu_mean <- apply(mu, 2, mean)
# make predictions binary
pred_binary <- ifelse(mu_mean <= 0.5, 0, 1)
correct_prediction <- as.numeric(pred_binary == d$Survived)

# calculate correct prediction rate
m5_pct_correct <- sum(correct_prediction) / length(correct_prediction)
# m5 confusion matrix
m5_confusion_matrix <- table(
  list(
    "Predicted" = pred_binary,
    "Actual" = d$Survived))
print("M5 accuracy:")
print(m5_pct_correct * 100)

print("M5 confusion matrix:")
print(m5_confusion_matrix)

# Summarise m5 again
precis(m5, depth = 3)
precis_plot(precis(m5, depth = 3))
```

> For our final model, we can see that the posterior predictions for passenger survival based on sex and class is quite good, with an accuracy rate of 79.7%, no doubt there are other factors in play that make this difficult to predict with 100% accuracy.
> The confusion matrix of our model indicates that it's overzealous in predicting that passengers did not survive (false negative) and our plots support that.
> 
> For our model parameters, we have Sex+Class and age, applying a linear relationship between age and survival is probably an oversimplification, as we saw previously that passengers who were very young were more likely to survive, and then again a peak around 40, and then declining again. Some of this could be due to the age of passengers in particular classes.
>
> For passenger sex, female passengers are more likely to survive than male, and for class, passengers are most likely to survive if they are in first class, followed by second class and then least likely in third class.
>
> Only female passengers in first and second class have a positive (and relatively large) effect on survival, all the other parameters have a negative effect on survival. Although the effect of a male, first class passenger is around zero and well within the distribution's estimated 89% confidence intervals.
>
> Obvioulsy this model is far from perfect, and making it more complex by including age as an effect on passenger class could increase the model's performance, but increasing the number of parameters also increases the risk of overfitting to the training data.
>
> When we apply this to the real life titanic situation, there are also other factors to consider, including the passengers proximity to the life boats when evacutation started, and even the passengers' percieved social status (I'm not sure if passengers had to show their tickets before boarding a life raft, so anyone could say they were first class if other people believed them).
> 
> Finally, if we were to explaion the model effects in real life, we might attribute the age effect and sex effect to the idea of "saving the women and children", and the class effects through the cynical lens of saving passengers who paid more for tickets and were more wealthy before the less wealthy. Although it is possible that first and second class passengers were just able to get to the life boats more quickly than third class passengers (which the image below offers some support for).

![Titanic passenger class accommodation location](https://www.encyclopedia-titanica.org/files/1/figure-one-side-view.gif "Titanic passenger class accommodation location")